{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Henil21/Natural_Language_processing/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwDuBbaSisuW"
      },
      "source": [
        "# Introduction to NLP fundamentals in Tensorflow\n",
        "\n",
        "The main goal of natural language processing (NLP) is to derive information from natural language.\n",
        "\n",
        "Natural language is a broad term but you can consider it to cover any of the following:\n",
        "\n",
        "* Text (such as that contained in an email, blog post, book, Tweet)\n",
        "* Speech (a conversation you have with a doctor, voice commands you give to a smart speaker)\n",
        "\n",
        "\n",
        "> Text -> turn into numbers -> build a model -> train the model to find patterns -> use patterns (make predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8ibmzorkgUh",
        "outputId": "5414ad2b-434e-47ff-a897-decd56970f49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-4a7c27e2-beed-f21f-bdb1-376734ef63b7)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi  -L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLlrQkK0qzyQ"
      },
      "source": [
        "## getting helper functions 🐚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXgPDc0T1AZ9",
        "outputId": "5729c9c7-cb89-437f-908c-a9f922d2570f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-07 16:29:09--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-05-07 16:29:09 (54.9 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcufFCQK1TXR"
      },
      "outputs": [],
      "source": [
        "# importing series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback,plot_loss_curves,compare_historys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrD-_7T32Lwh"
      },
      "source": [
        "## Get a text dataset\n",
        "\n",
        ">description of data set: text sample of tweet labelled as disaster or not disaster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34u4eCiy2s45",
        "outputId": "548aa919-4f7b-4d31-fda9-02fe913d04cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-07 16:29:15--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.136.128, 142.250.152.128, 142.250.128.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.136.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2023-05-07 16:29:15 (116 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "unzip_data('nlp_getting_started.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr8wl-RB3alt"
      },
      "source": [
        "## Visualizing Our Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TxOrKKBz4Ip2",
        "outputId": "c918c911-33f9-440b-f855-22df594345ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d3d5267-68a0-4f07-b229-9b21f37ea780\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d3d5267-68a0-4f07-b229-9b21f37ea780')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3d3d5267-68a0-4f07-b229-9b21f37ea780 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3d3d5267-68a0-4f07-b229-9b21f37ea780');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import pandas as pd\n",
        "train_dir=pd.read_csv(\"train.csv\")\n",
        "test_dir=pd.read_csv(\"test.csv\")\n",
        "train_dir.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "b42eb7Z05UnI",
        "outputId": "7368c9ad-e123-4522-cb01-157d9ef96112"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                    NaN   \n",
              "2227  3185       deluge                    NaN   \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                    NaN   \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81a76572-c9af-4b6d-b919-622b8a4b3fd0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81a76572-c9af-4b6d-b919-622b8a4b3fd0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81a76572-c9af-4b6d-b919-622b8a4b3fd0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81a76572-c9af-4b6d-b919-622b8a4b3fd0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# shuffling the training data\n",
        "train_shf=train_dir.sample(frac=1,random_state=42)\n",
        "train_shf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFhA4JEZ5_zB",
        "outputId": "c2f2cdc0-1a18-42b5-e47a-22335ea5ec55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_dir.target.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsSDNAEr9I8m",
        "outputId": "14564519-77d6-4aac-80ad-0e9080c4aba3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target:1 (real disaster)\n",
            "Text:\n",
            "70 Years After Atomic Bombs Japan Still Struggles With War Past: The anniversary of the devastation wrought b... http://t.co/1erd2FPryP\n",
            "\n",
            "----\n",
            "\n",
            "target:0 (not real disaster)\n",
            "Text:\n",
            "Someone walk with me to DQ ??\n",
            "I wanna Butterfinger Blizzard so bad??\n",
            "\n",
            "----\n",
            "\n",
            "target:0 (not real disaster)\n",
            "Text:\n",
            "HELLFIRE EP - SILENTMIND &amp; @_bookofdaniel  https://t.co/FKqJY3EzyG\n",
            "\n",
            "----\n",
            "\n",
            "target:1 (real disaster)\n",
            "Text:\n",
            "Rainstorm Update: Further North or Further South? http://t.co/50vdQ7A1M5 http://t.co/QH6oXfT9Ir\n",
            "\n",
            "----\n",
            "\n",
            "target:0 (not real disaster)\n",
            "Text:\n",
            "#BakeOffFriends #GBBO 'The one with the mudslide and the guy with the hat'\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# lets visualize some random training example\n",
        "import random\n",
        "random_index=random.randint(0, len(train_dir)-5)\n",
        "# create random index not higher than total number of samples\n",
        "for row in train_shf[[\"text\",\"target\"]][random_index:random_index+5].itertuples():\n",
        "  _,text,target=row\n",
        "  print(f\"target:{target}\",\"(real disaster)\" if target>0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB66_Pql9rLP"
      },
      "source": [
        "### Split data into training and validation sets ✅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpdf2XcKDLPG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8O4G8kpcDPhv"
      },
      "outputs": [],
      "source": [
        "# use train_test_split to split training data into training and validation sets\n",
        "train_sentences,val_sentences,train_labels,val_labels=train_test_split(train_shf[\"text\"].to_numpy(),\n",
        "                                                                       train_shf[\"target\"].to_numpy(),\n",
        "                                                                       test_size=0.1,\n",
        "                                                                       random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQRMKrN3EUHH",
        "outputId": "31aa5629-e8fc-4473-9321-4d2f9d0f34f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "val_sentences[:10]\n",
        "val_labels[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZWMAHGMT9Bl",
        "outputId": "910b772c-d709-413d-ddb7-7537bdeb56aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['DFR EP016 Monthly Meltdown - On Dnbheaven 2015.08.06 http://t.co/EjKRf8N8A8 #Drum and Bass #heavy #nasty http://t.co/SPHWE6wFI5',\n",
              "       'FedEx no longer to transport bioterror germs in wake of anthrax lab mishaps http://t.co/qZQc8WWwcN via @usatoday',\n",
              "       'Gunmen kill four in El Salvador bus attack: Suspected Salvadoran gang members killed four people and wounded s... http://t.co/CNtwB6ScZj',\n",
              "       '@camilacabello97 Internally and externally screaming',\n",
              "       'Radiation emergency #preparedness starts with knowing to: get inside stay inside and stay tuned http://t.co/RFFPqBAz2F via @CDCgov',\n",
              "       'Investigators rule catastrophic structural failure resulted in 2014 Virg.. Related Articles: http://t.co/Cy1LFeNyV8',\n",
              "       'How the West was burned: Thousands of wildfires ablaze in #California alone http://t.co/iCSjGZ9tE1 #climate #energy http://t.co/9FxmN0l0Bd',\n",
              "       \"Map: Typhoon Soudelor's predicted path as it approaches Taiwan; expected to make landfall over southern China by S\\x89Û_ http://t.co/JDVSGVhlIs\",\n",
              "       '\\x89Ûª93 blasts accused Yeda Yakub dies in Karachi of heart attack http://t.co/mfKqyxd8XG #Mumbai',\n",
              "       'My ears are bleeding  https://t.co/k5KnNwugwT'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "val_sentences[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fJhn8gosz1H"
      },
      "source": [
        "### Converting Text into number ⚡\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* Tokenization - A straight mapping from word or character or sub-word to a numerical value. There are three main levels of tokenization:\n",
        "1. Using word-level tokenization with the sentence \"I love TensorFlow\" might result in \"I\" being 0, \"love\" being 1 and \"TensorFlow\" being 2. In this case, every word in a sequence considered a single token.\n",
        "2. Character-level tokenization, such as converting the letters A-Z to values 1-26. In this case, every character in a sequence considered a single token.\n",
        "3. Sub-word tokenization is in between word-level and character-level tokenization. It involves breaking invidual words into smaller parts and then converting those smaller parts into numbers. For example, \"my favourite food is pineapple pizza\" might become \"my, fav, avour, rite, fo, oo, od, is, pin, ine, app, le, piz, za\". After doing this, these sub-words would then be mapped to a numerical value. In this case, every word could be considered multiple tokens.\n",
        "* Embeddings - An embedding is a representation of natural language which can be learned. Representation comes in the form of a feature vector. For example, the word \"dance\" could be represented by the 5-dimensional vector [-0.8547, 0.4559, -0.3332, 0.9877, 0.1112]. It's important to note here, the size of the feature vector is tuneable. There are two ways to use     embeddings:\n",
        "1. Create your own embedding - Once your text has been turned into numbers (required for an embedding), you can put them through an embedding layer (such as tf.keras.layers.Embedding) and an embedding representation will be learned during model training.\n",
        "2. Reuse a pre-learned embedding - Many pre-trained embeddings exist online. These pre-trained embeddings have often been learned on large corpuses of text (such as all of Wikipedia) and thus have a good underlying representation of natural language. You can use a pre-trained embedding to initialize your model and fine-tune it to your own specific task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tflXpkfs5RI"
      },
      "source": [
        "### Text vectorization (Tokenization)\n",
        "* The TextVectorization layer takes the following parameters:\n",
        "\n",
        "*  max_tokens - The maximum number of words in your vocabulary (e.g. 20000 or the number of unique words in your text), includes a value for OOV (out of vocabulary) tokens.\n",
        "* standardize - Method for standardizing text. Default is \"lower_and_strip_punctuation\" which lowers text and removes all punctuation marks.\n",
        "* split - How to split text, default is \"whitespace\" which splits on spaces.\n",
        "* ngrams - How many words to contain per token split, for example, ngrams=2 splits tokens into continuous sequences of 2.\n",
        "* output_mode - How to output tokens, can be \"int\" (integer mapping), \"binary\" (one-hot encoding), \"count\" or \"tf-idf\". See documentation for more.\n",
        "* output_sequence_length - Length of tokenized sequence to output. For example, if output_sequence_length=150, all tokenized sequences will be 150 tokens long.\n",
        "* pad_to_max_tokens - Defaults to False, if True, the output feature axis will be padded to max_tokens even if the number of unique tokens in the vocabulary is less than max_tokens. Only valid in certain modes, see docs for more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyxhK0RIu04A"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "#using default textvectorization parameters\n",
        "text_vec=TextVectorization(max_tokens=None, #how many different words are in our vocabaulary (automatically add <ODV>)\n",
        "                           standardize=\"lower_and_strip_punctuation\",#convert all to lower case and remove punctucations as it doesnot contribute much in output \n",
        "                           split=\"whitespace\",\n",
        "                           ngrams=None, #create groupe of n-word,\n",
        "                           output_mode=\"int\",\n",
        "                           output_sequence_length=None,#how long we want our sequences to be(how long a tweet can be)\n",
        "                          #  pad_to_max_tokens=True [not valid if max_token is set to None]\n",
        "                           )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLOF5V1s2_4g",
        "outputId": "2af0e495-4a86-4085-ff67-80ade44b77e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(train_sentences[0].split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tYt9qEv2Ppb",
        "outputId": "2b1c3c1c-00ed-47ef-f8d4-41f40cbd4905"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# find the average number of token(words) in the training tweet\n",
        "# Find average number of tokens (words) in training Tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnER7f7d3sK7"
      },
      "outputs": [],
      "source": [
        "# Setup text vectorization with custom variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                     split=\"whitespace\",\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gX5Fir1fSIe",
        "outputId": "70c5eef5-4977-476d-d5db-edf08534eb99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)\n",
        "\n",
        "# create a smple sentence and tokenize it\n",
        "sample_tweet=\"There's a flood in my street\"\n",
        "text_vectorizer([sample_tweet])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA8G3qCBhBpH",
        "outputId": "c50ca0b0-3066-48cf-ca61-6ce66210f6e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original text:\n",
            "After a violent afternoon storm more severe weather heads for Chicago tonight. Details ----&gt; http://t.co/6Peeip4y7W\n",
            "\n",
            " vectorized text tf.Tensor(\n",
            "[  43    3  357 1721   84   51  272  229 2096   10 1424  383 2495  741\n",
            "    1], shape=(15,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "# choose a random sentence from training dataset and tokenizing the,\n",
        "random_sentence=random.choice(train_sentences)\n",
        "print(f\"original text:\\n{random_sentence}\\n\\n vectorized text\",text_vectorizer(random_sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-36PiXxiOtE",
        "outputId": "7fe1563f-c8e3-4c77-aa33-9169eafc95f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of word in vocab 10000\n",
            "\n",
            "5 most comman word in  vocab ['', '[UNK]', 'the', 'a', 'in']\n",
            "\n",
            "5 least comman  word in vocab ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ],
      "source": [
        "# Get the unique words in vocabulary\n",
        "words_in_voc=text_vectorizer.get_vocabulary()\n",
        "top_5=words_in_voc[:5]\n",
        "bottom_5=words_in_voc[-5:]\n",
        "print(f\"number of word in vocab {len(words_in_voc)}\\n\")\n",
        "print(f\"5 most comman word in  vocab {top_5}\\n\")\n",
        "print(f\"5 least comman  word in vocab {bottom_5}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-V3xgL2yI5P"
      },
      "source": [
        "### Creating an Embedding Layer\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
        "\n",
        "The Parameters we care most about are\n",
        "* `input_dim` = the size of our vocabulary\n",
        "* `output_dim` = the size of the output embedding vector, eg:- a value of 100 would mean each token get represented by a vector of 100 long\n",
        "* `input_length` = The length of the sequences being passed to the embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqHcJYsoyZCO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length,#set the input shape\n",
        "                             output_dim=128,\n",
        "                             input_length=max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jrw4oTXh27Lb",
        "outputId": "b5b5ba19-dceb-4321-bfe1-3de7320e286c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "orignal text:\n",
            "Salvation Army hosts rally to reconnect fathers with children: The Salvation Army is hosting a back to school rallyÛ_ http://t.co/rDjpor3AZg\n"
          ]
        }
      ],
      "source": [
        "# Get random sentence\n",
        "random_sentence=random.choice(train_sentences)\n",
        "print(f\"orignal text:\\n{random_sentence}\")\n",
        "\n",
        "# embed the random sentence (turn it into dense vector of the fixed size)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAlaLMiv59PW",
        "outputId": "1d6d6ee0-b550-40b2-b4f4-bde98f9c27cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([ 0.0446749 , -0.04057628, -0.01240939,  0.01739873, -0.03687781,\n",
              "         0.03493551,  0.03528431, -0.0415516 ,  0.01274155,  0.04277835,\n",
              "        -0.03131666,  0.01182238,  0.04673585, -0.02285081,  0.0123657 ,\n",
              "        -0.04188626,  0.02435331,  0.00783161,  0.0196651 , -0.0461089 ,\n",
              "        -0.0360099 , -0.00897216,  0.02144365,  0.03952542,  0.0247239 ,\n",
              "         0.04894635,  0.02404788, -0.03733573, -0.01480088,  0.03881595,\n",
              "        -0.02796236,  0.0186591 , -0.00867822,  0.00380363,  0.0487071 ,\n",
              "        -0.02067112, -0.0440392 ,  0.00216711,  0.03284191,  0.0198997 ,\n",
              "        -0.04584963, -0.00975828, -0.00714908, -0.03814639, -0.02075733,\n",
              "        -0.03297029, -0.0287848 ,  0.03268846, -0.01765965,  0.02751484,\n",
              "        -0.02466332, -0.04856155,  0.00498266,  0.02011186, -0.00489664,\n",
              "        -0.01208273, -0.03520218,  0.04837526,  0.04283113, -0.00968809,\n",
              "         0.01162722, -0.04930142, -0.04667446,  0.01493445, -0.01635835,\n",
              "         0.03795138,  0.01645644, -0.00539229,  0.04251058,  0.00587772,\n",
              "        -0.01088331,  0.00637989, -0.02014863, -0.03271462,  0.02006948,\n",
              "        -0.01780961, -0.01359911, -0.00865237, -0.00142586,  0.00457321,\n",
              "         0.04052103, -0.01138236,  0.01484508,  0.0041422 , -0.01700605,\n",
              "        -0.0371278 , -0.04356457, -0.01894463,  0.03121809,  0.01031916,\n",
              "        -0.0299714 ,  0.01168828, -0.03235187,  0.02340117, -0.04881108,\n",
              "         0.01729243, -0.04468607, -0.02888823, -0.04431066,  0.00797627,\n",
              "        -0.04554318, -0.02543111,  0.01877544,  0.01076601,  0.00050346,\n",
              "         0.04074926,  0.00374408,  0.04488013,  0.01523959,  0.00952695,\n",
              "         0.03762429, -0.02073032, -0.01372607,  0.01099566, -0.04382671,\n",
              "         0.003787  , -0.04066721, -0.03201437,  0.04880342, -0.01308528,\n",
              "        -0.03306685, -0.04536576, -0.02799314, -0.03206158,  0.01608444,\n",
              "        -0.01084081,  0.02063343,  0.03005796], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " 'Salvation Army hosts rally to reconnect fathers with children: The Salvation Army is hosting a back to school rally\\x89Û_ http://t.co/rDjpor3AZg')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "#  check out single token embedding\n",
        "sample_embed[0][0],sample_embed[0][0].shape, random_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiAdKI4sggZo"
      },
      "source": [
        "### Modelling a text dataset\n",
        "\n",
        "Once you've got your inputs and outputs prepared, it's a matter of figuring out which machine learning model to build in between them to bridge the gap.\n",
        "\n",
        "Now that we've got a way to turn our text data into numbers, we can start to build machine learning models to model it.\n",
        "\n",
        "To get plenty of practice, we're going to build a series of different models, each as its own experiment. We'll then compare the results of each model and see which one performed best.\n",
        "\n",
        "More specifically, we'll be building the following:\n",
        "\n",
        "* Model 0: Naive Bayes (baseline)\n",
        "* Model 1: Feed-forward neural network (dense model)\n",
        "* Model 2: LSTM model\n",
        "* Model 3: GRU model\n",
        "* Model 4: Bidirectional-LSTM model\n",
        "* Model 5: 1D Convolutional Neural Network\n",
        "* Model 6: TensorFlow Hub Pretrained Feature Extractor\n",
        "* Model 7: Same as model 6 with 10% of training data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoLOpVz2cQLv"
      },
      "source": [
        "### Model 0: Getting a baseline\n",
        "As with all machine learning modelling experiments, it's important to create a baseline model so you've got a benchmark for future experiments to build upon.\n",
        "\n",
        "To create our baseline, we'll create a Scikit-Learn Pipeline using the TF-IDF (term frequency-inverse document frequency) formula to convert our words to numbers and then model them with the Multinomial Naive Bayes algorithm. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "UdlbaHYEcTG3",
        "outputId": "576dacbc-f33e-40d4-dab6-3e0fcb6fb8d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Convert text into number\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# our model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "    (\"tfidf\",TfidfVectorizer()),# convert words to number using tfidf\n",
        "    (\"clf\",MultinomialNB())# model the text\n",
        "])\n",
        "# fit the pipleine to the training data\n",
        "model_0.fit(train_sentences,train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNM8a0gErVyz",
        "outputId": "4ff25bde-7037-419d-ef80-033ccdf03a6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79.26509186351706"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "baseline_score=model_0.score(val_sentences,val_labels)\n",
        "# as we use .evaluate in tf for sklearn its .score\n",
        "baseline_score*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3eRPxdYr50Z",
        "outputId": "a7456017-b2fa-4016-b2f6-35781b3e3632"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "baseline_pred=model_0.predict(val_sentences)\n",
        "\n",
        "baseline_pred[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvgCgxFPsIVZ",
        "outputId": "1c377731-db25-4b33-f2dc-9e67d18fb03a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "train_labels[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqQUD_Lv237d"
      },
      "source": [
        "### Creating an evaluation function for our model experiments\n",
        "\n",
        "we could evaluate these as they are but since we're going to be evaluating several models in the same way going forward, let's create a helper function which takes an array of predictions and ground truth labels and computes the following:\n",
        "\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score\n",
        "> 🔑 Note: Since we're dealing with a classification problem, the above metrics are the most appropriate. If we were working with a regression problem, other metrics such as MAE (mean absolute error) would be a better choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2xo7Q694jMY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score,precision_recall_fscore_support\n",
        "def calculate_results(y_true,y_pred):\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy=accuracy_score(y_true,y_pred)*100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                   \"precision\":model_precision*100,\n",
        "                   \"recall\":model_recall*100,\n",
        "                   \"f1\":model_f1*100\n",
        "                   }\n",
        "  return model_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOL9F9Uv6tJ7",
        "outputId": "f67fd1a2-fa59-46d7-f4da-1b676f2eb298"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 81.11390004213173,\n",
              " 'recall': 79.26509186351706,\n",
              " 'f1': 78.6218975804955}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "bline=calculate_results(y_true=val_labels, y_pred=baseline_pred)\n",
        "bline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov7b6CHF9laY"
      },
      "source": [
        "### Model 1: A Simple Dense Model 🚀"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubyHRSWo-e5q"
      },
      "outputs": [],
      "source": [
        "#  Creating tensorboard callback\n",
        "from helper_functions import create_tensorboard_callback\n",
        "SAVE_DIR=\"model_logs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezBpoFe9Ald9"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "input=layers.Input(shape=(1,),dtype=tf.string) # inputs are 1-dimensional\n",
        "x=text_vectorizer(input) # convert strings into number \n",
        "x=embedding(x) # create an embedding of the numberized inputs\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "output=layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "model_1=tf.keras.Model(input,output,name=\"model_1_dense\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtGyM8QOG1cA",
        "outputId": "aa30f2d8-afb6-4d6d-8f0b-c9ab38bffc7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/simple_dense_model/20230507-162920\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 27s 90ms/step - loss: 0.6098 - accuracy: 0.6930 - val_loss: 0.5369 - val_accuracy: 0.7507\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.4403 - accuracy: 0.8164 - val_loss: 0.4693 - val_accuracy: 0.7861\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.3457 - accuracy: 0.8610 - val_loss: 0.4572 - val_accuracy: 0.7874\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.2843 - accuracy: 0.8899 - val_loss: 0.4665 - val_accuracy: 0.7927\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.2370 - accuracy: 0.9115 - val_loss: 0.4800 - val_accuracy: 0.7848\n"
          ]
        }
      ],
      "source": [
        "# model_1.summary()\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR, \n",
        "                                                                     experiment_name=\"simple_dense_model\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPP1-vG6501x"
      },
      "source": [
        "\n",
        "> use `GlobalAveragePooling1D` to layer before output layer if our data is 1D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0WV0IRm6gGw",
        "outputId": "e82ed941-dfb2-48d1-bc58-f75af98ed7f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "model_1_pred=probs=model_1.predict(val_sentences)\n",
        "model_1_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otyoC5xj6zJA",
        "outputId": "04f3168e-6460-4142-e091-d1cadf7f75ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.36844596],\n",
              "       [0.7556436 ],\n",
              "       [0.9974969 ],\n",
              "       [0.11594842],\n",
              "       [0.08837517],\n",
              "       [0.933863  ],\n",
              "       [0.8998223 ],\n",
              "       [0.99337924],\n",
              "       [0.9615011 ],\n",
              "       [0.2934877 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "model_1_pred[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSfkqVBI8pGT",
        "outputId": "0b3cb4ca-dadb-499e-a3d2-e7fac4632284"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=bool, numpy=\n",
              "array([ True, False,  True, False, False,  True,  True,  True,  True,\n",
              "        True])>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "tf.squeeze(tf.round(model_1_pred[:10]))==val_labels[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSNzkpPAn7gh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b994585-d80f-49be-9246-adc8620fe616"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "words_in_voc = text_vectorizer.get_vocabulary()\n",
        "len(words_in_voc),words_in_voc[:10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnuI9G6u1Nx7",
        "outputId": "1a460833-d93e-4cf1-bd8a-21270ba9c45b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Get weight matrix of embedding layer\n",
        "embed_weight=model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "embed_weight"
      ],
      "metadata": {
        "id": "sQFLOSlyKumL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7178cfc3-1dd7-49e7-b66d-7c1f32c383f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.00257788, -0.00067441, -0.02239144, ...,  0.04228447,\n",
              "         0.02287367,  0.00742683],\n",
              "       [-0.00587433, -0.03687649, -0.0493554 , ...,  0.02003003,\n",
              "        -0.01104028,  0.02986543],\n",
              "       [-0.02821171, -0.01904216,  0.01416913, ...,  0.03740098,\n",
              "         0.05573111, -0.03430087],\n",
              "       ...,\n",
              "       [ 0.03044374, -0.04529284, -0.04590565, ..., -0.00586065,\n",
              "        -0.00645094, -0.04605695],\n",
              "       [-0.06411184,  0.03376206, -0.0773836 , ..., -0.07480291,\n",
              "         0.05802172, -0.00536752],\n",
              "       [-0.09664132,  0.1081278 , -0.08619222, ..., -0.0875023 ,\n",
              "         0.05111773, -0.04251654]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# should be same size as vocab size and embedding dim\n",
        "print(embed_weight.shape)\n"
      ],
      "metadata": {
        "id": "6giEVfBcLWNQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1cd0723-b582-4f32-86a3-df12dd43579d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`projector.tensorflow.org`\n",
        "[word_embeddings guid](https://www.tensorflow.org/text/guide/word_embeddings)\n",
        "* lets see how we can visualize embedding matrix token representationbn"
      ],
      "metadata": {
        "id": "-lTo3uDrMPZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  import io\n",
        "\n",
        "# # Create output writers\n",
        "# out_v = io.open(\"embedding_vectors.tsv\", \"w\", encoding=\"utf-8\")\n",
        "# out_m = io.open(\"embedding_metadata.tsv\", \"w\", encoding=\"utf-8\")\n",
        "\n",
        "# # Write embedding vectors and words to file\n",
        "# for num, word in enumerate(words_in_voc):\n",
        "#   if num == 0: \n",
        "#      continue # skip padding token\n",
        "#   vec = embed_weight[num]\n",
        "#   out_m.write(word + \"\\n\") # write words to file\n",
        "#   out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\") # write corresponding word vector to file\n",
        "# out_v.close()\n",
        "# out_m.close()\n",
        "\n",
        "# # Download files locally to upload to Embedding Projector\n",
        "# try:\n",
        "#   from google.colab import files\n",
        "# except ImportError:\n",
        "#   pass\n",
        "# else:\n",
        "#   files.download(\"embedding_vectors.tsv\")\n",
        "#   files.download(\"embedding_metadata.tsv\")"
      ],
      "metadata": {
        "id": "NuW20-u4mZ5u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0a72be09-1e44-4ef8-8b4f-66faba9b94ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_28b5b9f6-d1fb-443c-acbd-a018e370cf1e\", \"embedding_vectors.tsv\", 15372931)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_07312ab6-0549-4022-878d-a3b52c554fa5\", \"embedding_metadata.tsv\", 80388)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Recurrent Neural Network (RNN's)⛹*\n",
        "\n",
        "\n",
        "* RNN's are the useful for sequence data.\n",
        "\n",
        "\n",
        "* The premise of recurrent neueal network is to use the representation of previous input aid the representation of a later input.🔗\n",
        "\n",
        "\n",
        "- [MIT Deep Learning Lecture on Recurrent Neural Networks](https://www.youtube.com/watch?v=SEnXr6v2ifU) - explains the background of recurrent neural networks and introduces LSTMs.\n",
        "\n",
        "- [Understanding LSTMs by Chris Olah](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) - an in-depth (and technical) look at the mechanics of the LSTM cell, possibly the most popular RNN building block.\n"
      ],
      "metadata": {
        "id": "NDC3hPJkj5ia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2 : LSTM\n",
        "> LSTM = Long short term memory\n",
        "\n",
        "* out structure of an RNN typically looks like this ⬇\n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> embedding -> Layers (RNNs/dense) -> Output (label probability)\n",
        "```"
      ],
      "metadata": {
        "id": "xI83zu0QZnf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM model\n",
        "from tensorflow.keras import layers\n",
        "inputs=layers.Input(shape=(1,),dtype='string')\n",
        "x=text_vectorizer(inputs)\n",
        "x=embedding(x)\n",
        "\n",
        "# print(x.shape)\n",
        "x=layers.LSTM(64,return_sequences=True)(x)\n",
        "# print(x.shape)\n",
        "\n",
        "# print(x.shape) \n",
        "x=layers.LSTM(64)(x)\n",
        "\n",
        "outputs=layers.Dense(64,activation='relu')(x)\n",
        "outputs=layers.Dense(1,activation='sigmoid')(x)\n",
        "model_2=tf.keras.Model(input,output,name=\"model_2_LSTM\")"
      ],
      "metadata": {
        "id": "7uMyXGCPa2hK"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afoy9f2WeXgs",
        "outputId": "fb03019a-293e-4404-d492-339748698482"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "yjLmSi1RecpE"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model_2.fit(train_sentences,\n",
        "                    train_labels,\n",
        "                    epochs=5,\n",
        "                    validation_data=(val_sentences,val_labels),\n",
        "                     callbacks=[create_tensorboard_callback(SAVE_DIR,'model_2_LSTM')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-4ppIates5g",
        "outputId": "1e18553b-a3aa-446e-d7e7-5d06661cba43"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20230507-185301\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 14s 58ms/step - loss: 0.0349 - accuracy: 0.9848 - val_loss: 1.7979 - val_accuracy: 0.7507\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.0338 - accuracy: 0.9853 - val_loss: 1.7986 - val_accuracy: 0.7559\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.0330 - accuracy: 0.9848 - val_loss: 1.7953 - val_accuracy: 0.7493\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.0329 - accuracy: 0.9861 - val_loss: 1.7874 - val_accuracy: 0.7507\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.0325 - accuracy: 0.9857 - val_loss: 1.7919 - val_accuracy: 0.7480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_pred_prob=model_2.predict(val_sentences)\n",
        "model_2_pred_prob[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khk0kHuVfWKa",
        "outputId": "66ca9950-f7e9-4d17-c3e9-21cd1848ec26"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.52837205],\n",
              "       [0.8222668 ],\n",
              "       [0.9997646 ],\n",
              "       [0.09048042],\n",
              "       [0.00769633],\n",
              "       [0.98879087],\n",
              "       [0.916943  ],\n",
              "       [0.99994767],\n",
              "       [0.9997093 ],\n",
              "       [0.61641175]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_preds=tf.squeeze(tf.round(model_2_pred_prob))\n",
        "model_2_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gm6o9bQfqeQ",
        "outputId": "b13efdbc-da29-4f13-cc9f-447771b9d1b1"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pAl5mr-f6NW",
        "outputId": "24e93bd6-ab35-4cb0-df2d-552146fac8ea"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_result=calculate_results(y_true=val_labels,\n",
        "                                 y_pred=model_2_preds)\n",
        "model_2_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHg-ocYLgKe5",
        "outputId": "a49a0763-b8fd-4130-d4d3-36d61491afae"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.55905511811024,\n",
              " 'precision': 77.5710931680431,\n",
              " 'recall': 77.55905511811024,\n",
              " 'f1': 77.45089775603932}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPC1VDB78U2l7zf0FhLad7l",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}