{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Henil21/Natural_Language_processing/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwDuBbaSisuW"
      },
      "source": [
        "# Introduction to NLP fundamentals in Tensorflow\n",
        "\n",
        "The main goal of natural language processing (NLP) is to derive information from natural language.\n",
        "\n",
        "Natural language is a broad term but you can consider it to cover any of the following:\n",
        "\n",
        "* Text (such as that contained in an email, blog post, book, Tweet)\n",
        "* Speech (a conversation you have with a doctor, voice commands you give to a smart speaker)\n",
        "\n",
        "\n",
        "> Text -> turn into numbers -> build a model -> train the model to find patterns -> use patterns (make predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8ibmzorkgUh",
        "outputId": "d5960a16-faa2-4dc8-b819-863801f73914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-a61bb77e-83bf-6099-8965-cc7bf931e986)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi  -L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLlrQkK0qzyQ"
      },
      "source": [
        "## getting helper functions üêö"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXgPDc0T1AZ9",
        "outputId": "85ba861e-d06c-4a35-a528-67f2c2463bc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-16 06:12:26--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‚Äòhelper_functions.py‚Äô\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-07-16 06:12:27 (59.3 MB/s) - ‚Äòhelper_functions.py‚Äô saved [10246/10246]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rcufFCQK1TXR"
      },
      "outputs": [],
      "source": [
        "# importing series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback,plot_loss_curves,compare_historys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrD-_7T32Lwh"
      },
      "source": [
        "## Get a text dataset\n",
        "\n",
        ">description of data set: text sample of tweet labelled as disaster or not disaster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34u4eCiy2s45",
        "outputId": "f85a1162-69fd-4120-8df9-d14cb50b2662"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-16 06:12:31--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.63.128, 142.250.31.128, 142.251.111.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.63.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‚Äònlp_getting_started.zip‚Äô\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2023-07-16 06:12:31 (128 MB/s) - ‚Äònlp_getting_started.zip‚Äô saved [607343/607343]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "unzip_data('nlp_getting_started.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9ear30XzMyTG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr8wl-RB3alt"
      },
      "source": [
        "## Visualizing Our Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "TxOrKKBz4Ip2",
        "outputId": "300118bd-c114-499f-96ff-d62f47d8f74a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-fde4aed1-683a-4ebe-b527-7480c1656417\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fde4aed1-683a-4ebe-b527-7480c1656417')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-720bc474-d7a0-482a-ad99-24d42a67e5fa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-720bc474-d7a0-482a-ad99-24d42a67e5fa')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-720bc474-d7a0-482a-ad99-24d42a67e5fa button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fde4aed1-683a-4ebe-b527-7480c1656417 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fde4aed1-683a-4ebe-b527-7480c1656417');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import pandas as pd\n",
        "train_dir=pd.read_csv(\"train.csv\")\n",
        "test_dir=pd.read_csv(\"test.csv\")\n",
        "train_dir.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "b42eb7Z05UnI",
        "outputId": "494af331-a41f-429e-ad28-5d67e9e81920"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                    NaN   \n",
              "2227  3185       deluge                    NaN   \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                    NaN   \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ¬â√õ√èThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-644e0b87-0f3d-4255-9a70-b7392dfe2e61\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ¬â√õ√èThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-644e0b87-0f3d-4255-9a70-b7392dfe2e61')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-435eba9d-98b8-4c40-8594-35957c93c707\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-435eba9d-98b8-4c40-8594-35957c93c707')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-435eba9d-98b8-4c40-8594-35957c93c707 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-644e0b87-0f3d-4255-9a70-b7392dfe2e61 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-644e0b87-0f3d-4255-9a70-b7392dfe2e61');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# shuffling the training data\n",
        "train_shf=train_dir.sample(frac=1,random_state=42)\n",
        "train_shf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFhA4JEZ5_zB",
        "outputId": "23cd1a01-63b3-4198-f865-cdafcadde875"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_dir.target.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsSDNAEr9I8m",
        "outputId": "f21dc177-907c-45c5-aae1-2ee3b2f6ea21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target:1 (real disaster)\n",
            "Text:\n",
            "Suicide Bomber Kills 13 At Saudi Mosque http://t.co/oZ1DS3Xu0D #Saudi #Tripoli #Libya\n",
            "\n",
            "----\n",
            "\n",
            "target:0 (not real disaster)\n",
            "Text:\n",
            "People are finally panicking about cable TV http://t.co/lCnW4EAD8v\n",
            "\n",
            "----\n",
            "\n",
            "target:1 (real disaster)\n",
            "Text:\n",
            "Map: Typhoon Soudelor's predicted path as it approaches Taiwan; expected to make landfall over southern China by... http://t.co/YvaFI3zuJx\n",
            "\n",
            "----\n",
            "\n",
            "target:0 (not real disaster)\n",
            "Text:\n",
            "Guns are for protection.. \n",
            "That shit really shouldn't be used unless your life in danger\n",
            "\n",
            "----\n",
            "\n",
            "target:0 (not real disaster)\n",
            "Text:\n",
            "#3: TITAN WarriorCord 100 Feet - Authentic Military 550 Paracord - MIL-C-5040-H Type III 7 Strand 5/16' di... http://t.co/EEjRMKtJ0R\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# lets visualize some random training example\n",
        "import random\n",
        "random_index=random.randint(0, len(train_dir)-5)\n",
        "# create random index not higher than total number of samples\n",
        "for row in train_shf[[\"text\",\"target\"]][random_index:random_index+5].itertuples():\n",
        "  _,text,target=row\n",
        "  print(f\"target:{target}\",\"(real disaster)\" if target>0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB66_Pql9rLP"
      },
      "source": [
        "### Split data into training and validation sets ‚úÖ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rpdf2XcKDLPG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8O4G8kpcDPhv"
      },
      "outputs": [],
      "source": [
        "# use train_test_split to split training data into training and validation sets\n",
        "train_sentences,val_sentences,train_labels,val_labels=train_test_split(train_shf[\"text\"].to_numpy(),\n",
        "                                                                       train_shf[\"target\"].to_numpy(),\n",
        "                                                                       test_size=0.1,\n",
        "                                                                       random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQRMKrN3EUHH",
        "outputId": "340b0b44-0f90-4c7d-a3f7-0fbe0a7b3857"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "val_sentences[:10]\n",
        "val_labels[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DuzjJfS1rrv",
        "outputId": "3d3d0eaf-0783-42e0-9b4b-d58e5e0d22af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "       '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "       'destroy the free fandom honestly',\n",
              "       'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "       '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "       'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_sentences[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZWMAHGMT9Bl",
        "outputId": "584e9e1b-2660-42c5-e7a8-21ccd5300136"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "val_labels.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fJhn8gosz1H"
      },
      "source": [
        "### Converting Text into number ‚ö°\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* Tokenization - A straight mapping from word or character or sub-word to a numerical value. There are three main levels of tokenization:\n",
        "1. Using word-level tokenization with the sentence \"I love TensorFlow\" might result in \"I\" being 0, \"love\" being 1 and \"TensorFlow\" being 2. In this case, every word in a sequence considered a single token.\n",
        "2. Character-level tokenization, such as converting the letters A-Z to values 1-26. In this case, every character in a sequence considered a single token.\n",
        "3. Sub-word tokenization is in between word-level and character-level tokenization. It involves breaking invidual words into smaller parts and then converting those smaller parts into numbers. For example, \"my favourite food is pineapple pizza\" might become \"my, fav, avour, rite, fo, oo, od, is, pin, ine, app, le, piz, za\". After doing this, these sub-words would then be mapped to a numerical value. In this case, every word could be considered multiple tokens.\n",
        "* Embeddings - An embedding is a representation of natural language which can be learned. Representation comes in the form of a feature vector. For example, the word \"dance\" could be represented by the 5-dimensional vector [-0.8547, 0.4559, -0.3332, 0.9877, 0.1112]. It's important to note here, the size of the feature vector is tuneable. There are two ways to use     embeddings:\n",
        "1. Create your own embedding - Once your text has been turned into numbers (required for an embedding), you can put them through an embedding layer (such as tf.keras.layers.Embedding) and an embedding representation will be learned during model training.\n",
        "2. Reuse a pre-learned embedding - Many pre-trained embeddings exist online. These pre-trained embeddings have often been learned on large corpuses of text (such as all of Wikipedia) and thus have a good underlying representation of natural language. You can use a pre-trained embedding to initialize your model and fine-tune it to your own specific task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tflXpkfs5RI"
      },
      "source": [
        "### Text vectorization (Tokenization)\n",
        "* The TextVectorization layer takes the following parameters:\n",
        "\n",
        "*  max_tokens - The maximum number of words in your vocabulary (e.g. 20000 or the number of unique words in your text), includes a value for OOV (out of vocabulary) tokens.\n",
        "* standardize - Method for standardizing text. Default is \"lower_and_strip_punctuation\" which lowers text and removes all punctuation marks.\n",
        "* split - How to split text, default is \"whitespace\" which splits on spaces.\n",
        "* ngrams - How many words to contain per token split, for example, ngrams=2 splits tokens into continuous sequences of 2.\n",
        "* output_mode - How to output tokens, can be \"int\" (integer mapping), \"binary\" (one-hot encoding), \"count\" or \"tf-idf\". See documentation for more.\n",
        "* output_sequence_length - Length of tokenized sequence to output. For example, if output_sequence_length=150, all tokenized sequences will be 150 tokens long.\n",
        "* pad_to_max_tokens - Defaults to False, if True, the output feature axis will be padded to max_tokens even if the number of unique tokens in the vocabulary is less than max_tokens. Only valid in certain modes, see docs for more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PyxhK0RIu04A"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "#using default textvectorization parameters\n",
        "text_vec=TextVectorization(max_tokens=None, #how many different words are in our vocabaulary (automatically add <ODV>)\n",
        "                           standardize=\"lower_and_strip_punctuation\",#convert all to lower case and remove punctucations as it doesnot contribute much in output\n",
        "                           split=\"whitespace\",\n",
        "                           ngrams=None, #create groupe of n-word,\n",
        "                           output_mode=\"int\",\n",
        "                           output_sequence_length=None,#how long we want our sequences to be(how long a tweet can be)\n",
        "                          #  pad_to_max_tokens=True [not valid if max_token is set to None]\n",
        "                           )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLOF5V1s2_4g",
        "outputId": "338ac9e2-23d4-4433-b838-deade1d6a93a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "len(train_sentences[0].split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tYt9qEv2Ppb",
        "outputId": "f278de50-ba8f-42cd-d840-46626a8a4d1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# find the average number of token(words) in the training tweet\n",
        "# Find average number of tokens (words) in training Tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jnER7f7d3sK7"
      },
      "outputs": [],
      "source": [
        "# Setup text vectorization with custom variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                     split=\"whitespace\",\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gX5Fir1fSIe",
        "outputId": "53589e3c-dddf-4095-c341-52e0ffb2815f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)\n",
        "\n",
        "# create a smple sentence and tokenize it\n",
        "sample_tweet=\"There's a flood in my street\"\n",
        "text_vectorizer([sample_tweet])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA8G3qCBhBpH",
        "outputId": "9b6f6c32-dd3d-45c5-9136-9ccf32f39783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original text:\n",
            "UNPREDICTABLE DISCONNECTED AND SOCIAL CASUALTY ARE MY FAVORITES HOW DO PEOPLE NOT LIKE THEM\n",
            "\n",
            " vectorized text tf.Tensor(\n",
            "[7183    1    7 1761  712   22   13 5662   62   68   57   34   25   93\n",
            "    0], shape=(15,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "# choose a random sentence from training dataset and tokenizing the,\n",
        "random_sentence=random.choice(train_sentences)\n",
        "print(f\"original text:\\n{random_sentence}\\n\\n vectorized text\",text_vectorizer(random_sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-36PiXxiOtE",
        "outputId": "f32c0e04-d91c-42e6-9b58-10016e497bde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of word in vocab 10000\n",
            "\n",
            "5 most comman word in  vocab ['', '[UNK]', 'the', 'a', 'in']\n",
            "\n",
            "5 least comman  word in vocab ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ],
      "source": [
        "# Get the unique words in vocabulary\n",
        "words_in_voc=text_vectorizer.get_vocabulary()\n",
        "top_5=words_in_voc[:5]\n",
        "bottom_5=words_in_voc[-5:]\n",
        "print(f\"number of word in vocab {len(words_in_voc)}\\n\")\n",
        "print(f\"5 most comman word in  vocab {top_5}\\n\")\n",
        "print(f\"5 least comman  word in vocab {bottom_5}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-V3xgL2yI5P"
      },
      "source": [
        "### Creating an Embedding Layer\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
        "\n",
        "The Parameters we care most about are\n",
        "* `input_dim` = the size of our vocabulary\n",
        "* `output_dim` = the size of the output embedding vector, eg:- a value of 100 would mean each token get represented by a vector of 100 long\n",
        "* `input_length` = The length of the sequences being passed to the embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kqHcJYsoyZCO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length,#set the input shape\n",
        "                             output_dim=128,\n",
        "                             input_length=max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jrw4oTXh27Lb",
        "outputId": "345ffb57-c57d-4c2b-919c-f9357e824e93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "orignal text:\n",
            "#news Britons rescued amid Himalaya floods http://t.co/kEPznhXHXd\n"
          ]
        }
      ],
      "source": [
        "# Get random sentence\n",
        "random_sentence=random.choice(train_sentences)\n",
        "print(f\"orignal text:\\n{random_sentence}\")\n",
        "\n",
        "# embed the random sentence (turn it into dense vector of the fixed size)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAlaLMiv59PW",
        "outputId": "dd6d64f6-f7b4-4dec-8208-56c2266a7d76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([-0.01160532, -0.01760237, -0.04184092, -0.04407846,  0.04875733,\n",
              "        -0.00588049, -0.02924928, -0.02756965, -0.0269789 , -0.03189565,\n",
              "        -0.03818621,  0.02887685,  0.02129215, -0.02272837,  0.00762744,\n",
              "        -0.03016251, -0.01395427, -0.006113  , -0.02270945, -0.02742483,\n",
              "        -0.03330179, -0.0162258 , -0.01706209,  0.03323879,  0.02217109,\n",
              "        -0.02841805, -0.0079926 , -0.01442591, -0.00752914, -0.01763443,\n",
              "        -0.04559371,  0.0060532 ,  0.04857535,  0.01777023, -0.02542138,\n",
              "        -0.01740067,  0.03861291,  0.00753601,  0.00331046, -0.00218325,\n",
              "         0.02259484,  0.04838986, -0.03849367,  0.01088142, -0.04144585,\n",
              "        -0.0319282 ,  0.03775727,  0.00952493,  0.0487793 ,  0.03310759,\n",
              "         0.02790171, -0.03960758,  0.01859156,  0.01923067, -0.015721  ,\n",
              "         0.04946709,  0.01211246,  0.0360002 ,  0.04993967, -0.0336499 ,\n",
              "         0.03703118,  0.04579041,  0.02611624, -0.04462754, -0.00028022,\n",
              "        -0.00211965,  0.00930561,  0.04948738,  0.03032423, -0.0317422 ,\n",
              "        -0.01757268,  0.01625066,  0.00927124,  0.00139274,  0.04087235,\n",
              "        -0.01064549,  0.04433439,  0.03573731, -0.0100073 , -0.00978433,\n",
              "         0.04030713,  0.01966662,  0.03464153,  0.02452961,  0.03905493,\n",
              "        -0.04293413,  0.02693195, -0.0026922 ,  0.01436636, -0.03353719,\n",
              "        -0.02089551,  0.00699186,  0.00759535,  0.04415232, -0.00219165,\n",
              "         0.00013097, -0.01497044,  0.01310997,  0.00760895,  0.04529066,\n",
              "        -0.01882956, -0.02772087,  0.0210809 , -0.02598479, -0.04993074,\n",
              "         0.03047581,  0.02239371, -0.02157115,  0.00483816,  0.0094839 ,\n",
              "         0.03998879, -0.00283974, -0.01807119,  0.0214381 ,  0.02848169,\n",
              "         0.00985245,  0.01449081,  0.04815931,  0.01802727,  0.00041676,\n",
              "         0.03500651,  0.00480742, -0.01376277,  0.03435277, -0.04158466,\n",
              "         0.01080168,  0.02007267, -0.01363094], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " '#news Britons rescued amid Himalaya floods http://t.co/kEPznhXHXd')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "#  check out single token embedding\n",
        "sample_embed[0][0],sample_embed[0][0].shape, random_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiAdKI4sggZo"
      },
      "source": [
        "### Modelling a text dataset\n",
        "\n",
        "Once you've got your inputs and outputs prepared, it's a matter of figuring out which machine learning model to build in between them to bridge the gap.\n",
        "\n",
        "Now that we've got a way to turn our text data into numbers, we can start to build machine learning models to model it.\n",
        "\n",
        "To get plenty of practice, we're going to build a series of different models, each as its own experiment. We'll then compare the results of each model and see which one performed best.\n",
        "\n",
        "More specifically, we'll be building the following:\n",
        "\n",
        "* Model 0: Naive Bayes (baseline)\n",
        "* Model 1: Feed-forward neural network (dense model)\n",
        "* Model 2: LSTM model\n",
        "* Model 3: GRU model\n",
        "* Model 4: Bidirectional-LSTM model\n",
        "* Model 5: 1D Convolutional Neural Network\n",
        "* Model 6: TensorFlow Hub Pretrained Feature Extractor\n",
        "* Model 7: Same as model 6 with 10% of training data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoLOpVz2cQLv"
      },
      "source": [
        "### Model 0: Getting a baseline\n",
        "As with all machine learning modelling experiments, it's important to create a baseline model so you've got a benchmark for future experiments to build upon.\n",
        "\n",
        "To create our baseline, we'll create a Scikit-Learn Pipeline using the TF-IDF (term frequency-inverse document frequency) formula to convert our words to numbers and then model them with the Multinomial Naive Bayes algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "UdlbaHYEcTG3",
        "outputId": "9424d743-a173-4a6e-fc93-0eccc73d4609"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Convert text into number\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# our model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "    (\"tfidf\",TfidfVectorizer()),# convert words to number using tfidf\n",
        "    (\"clf\",MultinomialNB())# model the text\n",
        "])\n",
        "# fit the pipleine to the training data\n",
        "model_0.fit(train_sentences,train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNM8a0gErVyz",
        "outputId": "8e777c8a-7f2f-4cd6-fb4a-3a0c0a9e9224"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79.26509186351706"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "baseline_score=model_0.score(val_sentences,val_labels)\n",
        "# as we use .evaluate in tf for sklearn its .score\n",
        "baseline_score*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3eRPxdYr50Z",
        "outputId": "ba5b6179-079e-4757-833f-f573c92865fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "baseline_pred=model_0.predict(val_sentences)\n",
        "\n",
        "baseline_pred[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvgCgxFPsIVZ",
        "outputId": "626dbc2d-9115-454b-e69d-71529d95b5b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "train_labels[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqQUD_Lv237d"
      },
      "source": [
        "### Creating an evaluation function for our model experiments\n",
        "\n",
        "we could evaluate these as they are but since we're going to be evaluating several models in the same way going forward, let's create a helper function which takes an array of predictions and ground truth labels and computes the following:\n",
        "\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score\n",
        "> üîë Note: Since we're dealing with a classification problem, the above metrics are the most appropriate. If we were working with a regression problem, other metrics such as MAE (mean absolute error) would be a better choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Q2xo7Q694jMY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score,precision_recall_fscore_support\n",
        "def calculate_results(y_true,y_pred):\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy=accuracy_score(y_true,y_pred)*100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                   \"precision\":model_precision*100,\n",
        "                   \"recall\":model_recall*100,\n",
        "                   \"f1\":model_f1*100\n",
        "                   }\n",
        "  return model_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOL9F9Uv6tJ7",
        "outputId": "d647df8c-20f1-4745-bbbd-2cbd1bd0ebc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 81.11390004213173,\n",
              " 'recall': 79.26509186351706,\n",
              " 'f1': 78.6218975804955}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "bline=calculate_results(y_true=val_labels, y_pred=baseline_pred)\n",
        "bline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov7b6CHF9laY"
      },
      "source": [
        "### Model 1: A Simple Dense Model üöÄ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ubyHRSWo-e5q"
      },
      "outputs": [],
      "source": [
        "#  Creating tensorboard callback\n",
        "from helper_functions import create_tensorboard_callback\n",
        "SAVE_DIR=\"model_logs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ezBpoFe9Ald9"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "input=layers.Input(shape=(1,),dtype=tf.string) # inputs are 1-dimensional\n",
        "x=text_vectorizer(input) # convert strings into number\n",
        "x=embedding(x) # create an embedding of the numberized inputs\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "output=layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "model_1=tf.keras.Model(input,output,name=\"model_1_dense\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtGyM8QOG1cA",
        "outputId": "0132cd50-62d1-4a4e-9a96-0295b7ff34d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/simple_dense_model/20230716-061236\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 33s 127ms/step - loss: 0.6115 - accuracy: 0.6935 - val_loss: 0.5343 - val_accuracy: 0.7572\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.4405 - accuracy: 0.8189 - val_loss: 0.4736 - val_accuracy: 0.7874\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.3461 - accuracy: 0.8587 - val_loss: 0.4586 - val_accuracy: 0.7913\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.2833 - accuracy: 0.8894 - val_loss: 0.4645 - val_accuracy: 0.7953\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.2363 - accuracy: 0.9120 - val_loss: 0.4785 - val_accuracy: 0.7874\n"
          ]
        }
      ],
      "source": [
        "# model_1.summary()\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"simple_dense_model\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPP1-vG6501x"
      },
      "source": [
        "\n",
        "> use `GlobalAveragePooling1D` to layer before output layer if our data is 1D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0WV0IRm6gGw",
        "outputId": "2d170d57-b4bd-4c49-fcf0-b80eaf928535"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "model_1_pred=probs=model_1.predict(val_sentences)\n",
        "model_1_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otyoC5xj6zJA",
        "outputId": "3d88daeb-2c65-4957-dc78-fce6204d8788"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4435298 ],\n",
              "       [0.7993007 ],\n",
              "       [0.99790937],\n",
              "       [0.12380005],\n",
              "       [0.12031657],\n",
              "       [0.9516888 ],\n",
              "       [0.9102538 ],\n",
              "       [0.9912497 ],\n",
              "       [0.9716827 ],\n",
              "       [0.272072  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "model_1_pred[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSfkqVBI8pGT",
        "outputId": "1d71a633-e555-42e2-f815-c8aee6ea7d3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=bool, numpy=\n",
              "array([ True, False,  True, False, False,  True,  True,  True,  True,\n",
              "        True])>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "tf.squeeze(tf.round(model_1_pred[:10]))==val_labels[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSNzkpPAn7gh",
        "outputId": "13cc6416-2c5d-4c47-defc-cf3c2171d851"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "words_in_voc = text_vectorizer.get_vocabulary()\n",
        "len(words_in_voc),words_in_voc[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnuI9G6u1Nx7",
        "outputId": "a24540dc-4d1a-480f-983a-c6d08441313f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "sQFLOSlyKumL"
      },
      "outputs": [],
      "source": [
        "# #  Get weight matrix of embedding layer\n",
        "# embed_weight=model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "# embed_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "6giEVfBcLWNQ"
      },
      "outputs": [],
      "source": [
        "# # should be same size as vocab size and embedding dim\n",
        "# print(embed_weight.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lTo3uDrMPZL"
      },
      "source": [
        "`projector.tensorflow.org`\n",
        "[word_embeddings guid](https://www.tensorflow.org/text/guide/word_embeddings)\n",
        "* lets see how we can visualize embedding matrix token representationbn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "NuW20-u4mZ5u"
      },
      "outputs": [],
      "source": [
        "#  import io\n",
        "\n",
        "# # Create output writers\n",
        "# out_v = io.open(\"embedding_vectors.tsv\", \"w\", encoding=\"utf-8\")\n",
        "# out_m = io.open(\"embedding_metadata.tsv\", \"w\", encoding=\"utf-8\")\n",
        "\n",
        "# # Write embedding vectors and words to file\n",
        "# for num, word in enumerate(words_in_voc):\n",
        "#   if num == 0:\n",
        "#      continue # skip padding token\n",
        "#   vec = embed_weight[num]\n",
        "#   out_m.write(word + \"\\n\") # write words to file\n",
        "#   out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\") # write corresponding word vector to file\n",
        "# out_v.close()\n",
        "# out_m.close()\n",
        "\n",
        "# # Download files locally to upload to Embedding Projector\n",
        "# try:\n",
        "#   from google.colab import files\n",
        "# except ImportError:\n",
        "#   pass\n",
        "# else:\n",
        "#   files.download(\"embedding_vectors.tsv\")\n",
        "#   files.download(\"embedding_metadata.tsv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDC3hPJkj5ia"
      },
      "source": [
        "## *Recurrent Neural Network (RNN's)‚õπ*\n",
        "\n",
        "\n",
        "* RNN's are the useful for sequence data.\n",
        "\n",
        "\n",
        "* The premise of recurrent neueal network is to use the representation of previous input aid the representation of a later input.üîó\n",
        "\n",
        "\n",
        "- [MIT Deep Learning Lecture on Recurrent Neural Networks](https://www.youtube.com/watch?v=SEnXr6v2ifU) - explains the background of recurrent neural networks and introduces LSTMs.\n",
        "\n",
        "- [Understanding LSTMs by Chris Olah](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) - an in-depth (and technical) look at the mechanics of the LSTM cell, possibly the most popular RNN building block.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI83zu0QZnf7"
      },
      "source": [
        "### Model 2 : LSTM\n",
        "> LSTM = Long short term memory\n",
        "\n",
        "* out structure of an RNN typically looks like this ‚¨á\n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> embedding -> Layers (RNNs/dense) -> Output (label probability)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "7uMyXGCPa2hK"
      },
      "outputs": [],
      "source": [
        "# LSTM model\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "inputs=layers.Input(shape=(1,),dtype='string')\n",
        "x=text_vectorizer(inputs)\n",
        "x=embedding(x)\n",
        "\n",
        "# print(x.shape)\n",
        "x=layers.LSTM(64,return_sequences=True)(x)\n",
        "# print(x.shape)\n",
        "\n",
        "# print(x.shape)\n",
        "x=layers.LSTM(64,return_sequences=True)(x)\n",
        "x=layers.LSTM(64)(x)\n",
        "\n",
        "\n",
        "outputs=layers.Dense(64,activation='relu')(x)\n",
        "outputs=layers.Dense(1,activation='sigmoid')(x)\n",
        "model_2=tf.keras.Model(input,output,name=\"model_2_LSTM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afoy9f2WeXgs",
        "outputId": "660b751d-8592-4d5b-e0c8-e6034ff32a13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "yjLmSi1RecpE"
      },
      "outputs": [],
      "source": [
        "model_2.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-4ppIates5g",
        "outputId": "f835514d-1f59-4bac-8b53-9dad4b4b0c52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20230716-061321\n",
            "Epoch 1/10\n",
            "215/215 [==============================] - 11s 49ms/step - loss: 0.2005 - accuracy: 0.9270 - val_loss: 0.5138 - val_accuracy: 0.7861\n",
            "Epoch 2/10\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.1719 - accuracy: 0.9372 - val_loss: 0.5427 - val_accuracy: 0.7887\n",
            "Epoch 3/10\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1481 - accuracy: 0.9456 - val_loss: 0.5746 - val_accuracy: 0.7835\n",
            "Epoch 4/10\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.1290 - accuracy: 0.9553 - val_loss: 0.6136 - val_accuracy: 0.7848\n",
            "Epoch 5/10\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.1135 - accuracy: 0.9583 - val_loss: 0.6488 - val_accuracy: 0.7835\n",
            "Epoch 6/10\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.1023 - accuracy: 0.9632 - val_loss: 0.6863 - val_accuracy: 0.7782\n",
            "Epoch 7/10\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0912 - accuracy: 0.9685 - val_loss: 0.7289 - val_accuracy: 0.7664\n",
            "Epoch 8/10\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0837 - accuracy: 0.9696 - val_loss: 0.7661 - val_accuracy: 0.7756\n",
            "Epoch 9/10\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0764 - accuracy: 0.9737 - val_loss: 0.8224 - val_accuracy: 0.7677\n",
            "Epoch 10/10\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.0720 - accuracy: 0.9729 - val_loss: 0.8412 - val_accuracy: 0.7690\n"
          ]
        }
      ],
      "source": [
        "history=model_2.fit(train_sentences,\n",
        "                    train_labels,\n",
        "                    epochs=10,\n",
        "                    validation_data=(val_sentences,val_labels),\n",
        "                     callbacks=[create_tensorboard_callback(SAVE_DIR,'model_2_LSTM')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khk0kHuVfWKa",
        "outputId": "405e8e44-d39e-4034-970d-59d6becd7316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.3123344e-01],\n",
              "       [6.6302085e-01],\n",
              "       [9.9969566e-01],\n",
              "       [4.7636144e-02],\n",
              "       [3.3173655e-04],\n",
              "       [9.9143195e-01],\n",
              "       [7.7191532e-01],\n",
              "       [9.9999666e-01],\n",
              "       [9.9999368e-01],\n",
              "       [6.2317878e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "model_2_pred_prob=model_2.predict(val_sentences)\n",
        "model_2_pred_prob[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gm6o9bQfqeQ",
        "outputId": "d96fcbe9-c9a4-46ce-f681-ddbaa30cc4a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "model_2_preds=tf.squeeze(tf.round(model_2_pred_prob))\n",
        "model_2_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pAl5mr-f6NW",
        "outputId": "64af6659-8b4d-424d-ead8-63bf71ca3ccf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "val_labels[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHg-ocYLgKe5",
        "outputId": "176cb243-f1bc-42f7-a452-350280df785d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.9028871391076,\n",
              " 'precision': 77.06028054440213,\n",
              " 'recall': 76.9028871391076,\n",
              " 'f1': 76.69342344352704}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "model_2_result=calculate_results(y_true=val_labels,\n",
        "                                 y_pred=model_2_preds)\n",
        "model_2_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UZRIcbGQdaw"
      },
      "source": [
        "### Lets Try GRU üåÉ\n",
        "```\n",
        "GRU is similar as LSTM but with less parameters\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "HPB7qojjQ9B2"
      },
      "outputs": [],
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_3\")\n",
        "\n",
        "# Build an RNN using the GRU cell\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_3_embedding(x)\n",
        "# x = layers.GRU(64, return_sequences=True) # stacking recurrent cells requires return_sequences=True\n",
        "x = layers.GRU(64)(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer after GRU cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWzi2jylVeUP",
        "outputId": "03e9b52f-6a2c-41e6-f6d7-1842404f72de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Z-NfJHbXHh5",
        "outputId": "35a9e94b-165c-407b-cee0-deaf28fcc584"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/GRU/20230716-061350\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 15s 52ms/step - loss: 0.5263 - accuracy: 0.7284 - val_loss: 0.4566 - val_accuracy: 0.7835\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.3174 - accuracy: 0.8692 - val_loss: 0.4903 - val_accuracy: 0.7769\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.2165 - accuracy: 0.9183 - val_loss: 0.5571 - val_accuracy: 0.7690\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.1541 - accuracy: 0.9460 - val_loss: 0.6203 - val_accuracy: 0.7756\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1172 - accuracy: 0.9606 - val_loss: 0.6001 - val_accuracy: 0.7690\n"
          ]
        }
      ],
      "source": [
        "# Compile GRU model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\")])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the validation data\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs.shape, model_3_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1AiwWxavDBc",
        "outputId": "aa021a89-a988-4431-e998-a8f59304913e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1),\n",
              " array([[0.38547307],\n",
              "        [0.9191302 ],\n",
              "        [0.9969579 ],\n",
              "        [0.16084224],\n",
              "        [0.01584137],\n",
              "        [0.988111  ],\n",
              "        [0.75145245],\n",
              "        [0.99661535],\n",
              "        [0.99685955],\n",
              "        [0.3750981 ]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities to prediction classes\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILoorFj9u-nu",
        "outputId": "be8708f5-a8ef-4fd5-e524-061a1d5a3f9f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcuate model_3 results\n",
        "model_3_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUkXbHnsu6LF",
        "outputId": "8d0c8307-4931-4e31-ec82-1e00d09d4d02"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.9028871391076,\n",
              " 'precision': 76.91242349168364,\n",
              " 'recall': 76.9028871391076,\n",
              " 'f1': 76.78647757387915}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorflow Bi-direction LSTM(RNN) ‚ú®\n",
        "Look at us go! We've already built two RNN's with GRU and LSTM cells. Now we're going to look into another kind of RNN, the bidirectional RNN.\n",
        "\n",
        "A standard RNN will process a sequence from left to right, where as a bidirectional RNN will process the sequence from left to right and then again from right to left.\n",
        "\n",
        "Intuitively, this can be thought of as if you were reading a sentence for the first time in the normal fashion (left to right) but for some reason it didn't make sense so you traverse back through the words and go back over them again (right to left).\n",
        "\n",
        "In practice, many sequence models often see and improvement in performance when using bidirectional RNN's.\n",
        "\n",
        "However, this improvement in performance often comes at the cost of longer training times and increased model parameters (since the model goes left to right and right to left, the number of trainable parameters doubles).\n",
        "\n",
        "Okay enough talk, let's build a bidirectional RNN.\n",
        "\n",
        "Once again, TensorFlow helps us out by providing the tensorflow.keras.layers.Bidirectional class. We can use the Bidirectional class to wrap our existing RNNs, instantly making them bidirectional"
      ],
      "metadata": {
        "id": "6cbHd1_b_tXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "inputs=layers.Input(shape=(1,),dtype=\"string\")\n",
        "x=text_vectorizer(inputs)\n",
        "x=embedding(x)\n",
        "# x=layers.Bidirectional(layers.LSTM(64,return_sequences=True))(x) #layers.Bidirectional works with any LSTM\n",
        "# print(x.shape)\n",
        "x=layers.Bidirectional(layers.GRU(64))(x)\n",
        "outputs=layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "model_4=tf.keras.Model(inputs,outputs,name=\"model_4_bidirectional\")\n"
      ],
      "metadata": {
        "id": "lm43Rr3-AIiQ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmvA1C9PDStD",
        "outputId": "93410482-d53b-47da-ab02-281e7561977c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              74496     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,354,625\n",
            "Trainable params: 1,354,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SFylMRqDEZWk"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_4_history=model_4.fit(train_sentences,\n",
        "                            train_labels,\n",
        "                            epochs=5,\n",
        "                            validation_data=(val_sentences,val_labels),\n",
        "                            callbacks=[create_tensorboard_callback(SAVE_DIR, \"model_4_bidirectional\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezi4PU73E-G3",
        "outputId": "8f0ff92a-e828-43b6-f075-ef43261fe52a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20230716-061416\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 16s 51ms/step - loss: 0.1168 - accuracy: 0.9600 - val_loss: 0.9579 - val_accuracy: 0.7703\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0693 - accuracy: 0.9730 - val_loss: 0.8424 - val_accuracy: 0.7664\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.0612 - accuracy: 0.9743 - val_loss: 0.9138 - val_accuracy: 0.7638\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0603 - accuracy: 0.9765 - val_loss: 0.9181 - val_accuracy: 0.7572\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.0541 - accuracy: 0.9764 - val_loss: 1.0616 - val_accuracy: 0.7572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert pred probs to pred lables\n",
        "model_4_pred_probs=model_4.predict(val_sentences)\n",
        "# model_4_pred_probs[:10]\n",
        "model_preds=tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwe5rMEfF-KS",
        "outputId": "f5302800-a459-4408-e18f-aac7087eee4b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_results=calculate_results(y_true=val_labels,\n",
        "                                  y_pred=model_preds)\n",
        "model_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AKBQmyBGcHw",
        "outputId": "6e7c9a6c-3ae7-4952-eeda-2581a6924393"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.7217847769029,\n",
              " 'precision': 75.7104469267424,\n",
              " 'recall': 75.7217847769029,\n",
              " 'f1': 75.60477242612443}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conv1D üêõ"
      ],
      "metadata": {
        "id": "2gP6h8ayP-TF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_test=embedding(text_vectorizer(['this is a test sentence']))\n",
        "conv_1d=layers.Conv1D(filters=32,\n",
        "                      kernel_size=5,\n",
        "                      activation='relu',\n",
        "                      padding='valid')\n",
        "conv_1d_output=conv_1d(embedding_test)\n",
        "max_pool=layers.GlobalMaxPool1D()\n",
        "max_pool_output=max_pool(conv_1d_output)"
      ],
      "metadata": {
        "id": "OvzNQlwjQClF"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting shape\n",
        "embedding_test.shape,conv_1d_output.shape,max_pool_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM_dKfGnRuBW",
        "outputId": "1a51d695-9d46-4d85-c5b2-882d231eb7c9"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 1-D convolutional layer to model sequences"
      ],
      "metadata": {
        "id": "XICBtXBbXtYj"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input=layers.Input(shape=(1,),dtype=tf.string)\n",
        "x=text_vectorizer(inputs)\n",
        "x=embedding(x)\n",
        "x=layers.Conv1D(filters=64,kernel_size=5,activation='relu',padding='valid')(x)\n",
        "x=layers.GlobalMaxPool1D()(x)\n",
        "outputs=layers.Dense(1,activation='sigmoid')(x)\n",
        "model_5=tf.keras.Model(inputs,outputs,name=\"model_5_conv_1D\")\n",
        "\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                            optimizer=tf.keras.optimizers.Adam(),\n",
        "                             metrics=[\"accuracy\"])\n",
        "\n",
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARrVv3wOYdyT",
        "outputId": "a1fff5ac-8fc1-436c-b549-5225b3eafcce"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_conv_1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 11, 64)            41024     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_history=model_5.fit(train_sentences,\n",
        "                            train_labels,\n",
        "                            epochs=5,\n",
        "                            validation_data=(val_sentences,val_labels),\n",
        "                            callbacks=[create_tensorboard_callback(SAVE_DIR, \"Conv1D\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVfAHktnaa34",
        "outputId": "55f2432e-fe84-4db7-98ed-626b0cb8ac28"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20230716-061504\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 13s 46ms/step - loss: 0.1074 - accuracy: 0.9660 - val_loss: 0.9485 - val_accuracy: 0.7638\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0668 - accuracy: 0.9747 - val_loss: 1.1093 - val_accuracy: 0.7612\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.0582 - accuracy: 0.9753 - val_loss: 1.1637 - val_accuracy: 0.7612\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0531 - accuracy: 0.9772 - val_loss: 1.2473 - val_accuracy: 0.7533\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.0493 - accuracy: 0.9783 - val_loss: 1.2999 - val_accuracy: 0.7612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_pred_pro=model_5.predict(val_sentences)\n",
        "model_5_pred_pro[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJBu6HmUbM8_",
        "outputId": "ee0a475f-d1bb-4d93-d80e-dbabe4cd9c57"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.1464747e-01],\n",
              "       [6.4758664e-01],\n",
              "       [9.9982589e-01],\n",
              "       [5.8142170e-02],\n",
              "       [5.5049571e-07],\n",
              "       [9.9082464e-01],\n",
              "       [9.9380869e-01],\n",
              "       [9.9993730e-01],\n",
              "       [1.0000000e+00],\n",
              "       [9.6893811e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_preds=tf.squeeze(tf.round(model_5_pred_pro))\n",
        "model_5_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bekNR3DTbcfL",
        "outputId": "7f43cba3-01f2-461f-8cee-79b3ddcf4f36"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model_5 prediction\n",
        "model_5_results=calculate_results(y_true=val_labels,\n",
        "                                                        y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29Qvb7fubrmy",
        "outputId": "c1a17ae9-a717-4e9a-a104-b64e7d944300"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.11548556430446,\n",
              " 'precision': 76.18883943071393,\n",
              " 'recall': 76.11548556430446,\n",
              " 'f1': 75.93763358258425}"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pre-trained sentence encoder ‚úà\n",
        "\n",
        "For all of the previous deep learning models we've built and trained, we've created and used our own embeddings from scratch each time.\n",
        "\n",
        "However, a common practice is to leverage pretrained embeddings through transfer learning. This is one of the main benefits of using deep models: being able to take what one (often larger) model has learned (often on a large amount of data) and adjust it for our own use case.\n",
        "\n",
        "For our next model, instead of using our own embedding layer, we're going to replace it with a pretrained embedding layer.\n",
        "\n",
        "More specifically, we're going to be using the Universal Sentence Encoder from TensorFlow Hub (a great resource containing a plethora of pretrained model resources for a variety of tasks).\n",
        "\n",
        "> üîë Note: There are many different pretrained text embedding options on TensorFlow Hub, however, some require different levels of text preprocessing than others. Best to experiment with a few and see which best suits your use case."
      ],
      "metadata": {
        "id": "S9B8aujq6N3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfIi1u5FV6B4",
        "outputId": "612d4803-0ad9-4287-87f5-0ef775c90811"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The feature extractor model we're building through the eyes of an encoder/decoder* model.*\n",
        "\n",
        ">üîë Note: An encoder is the name for a model which converts raw data such as text into a numerical representation (feature vector), a decoder converts the numerical representation to a desired output.\n",
        "\n",
        "As usual, this is best demonstrated with an example.\n",
        "\n",
        "We can load in a TensorFlow Hub module using the hub.load() method and passing it the target URL of the module we'd like to use, in our case, it's \"https://tfhub.dev/google/universal-sentence-encoder/4\".\n",
        "\n",
        "Let's load the Universal Sentence Encoder model and test it on a couple of sentences"
      ],
      "metadata": {
        "id": "dfw28B8PXO2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "embed=hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n",
        "embed_sample=embed([sample_sentence,\n",
        "                    \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "\n",
        "\n",
        "embed_sample"
      ],
      "metadata": {
        "id": "WxdBLZp56U59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a5238a-e38e-46fb-f1e2-df174d15c1cf"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 512), dtype=float32, numpy=\n",
              "array([[-0.01157028,  0.0248591 ,  0.02878048, ..., -0.00186124,\n",
              "         0.02315826, -0.01485021],\n",
              "       [ 0.03596688, -0.08579469, -0.01152738, ..., -0.03414334,\n",
              "         0.02816022, -0.00878943]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_encoder_layer=hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                                                    input_shape=(),\n",
        "                                                                    dtype=tf.string,\n",
        "                                                                    trainable=False,\n",
        "                                                                    name=\"USE\"\n",
        "                                                                    )"
      ],
      "metadata": {
        "id": "MPe2RrsmXoA-"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6=tf.keras.Sequential([\n",
        "    sentence_encoder_layer,\n",
        "    layers.Dense(1,activation='sigmoid')\n",
        "],name='model_6_USE')\n",
        "model_6.compile(loss='binary_crossentropy',\n",
        "                            optimizer=tf.keras.optimizers.Adam(),\n",
        "                            metrics=['accuracy']\n",
        "                                )\n",
        "model_6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPHDNJIebdOy",
        "outputId": "2bbc5eb1-5fb6-4ee6-eedd-b51bdc43db71"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,798,337\n",
            "Trainable params: 513\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHLs0x4qUTGoTXVryS0FPW",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}